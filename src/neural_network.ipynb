{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test data\n",
    "train_data_path = '../resources/train.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquin/Desktop/nlp/nlp/nlpenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 618us/step - loss: 7523160576.0000 - mae: 34797.7852 - val_loss: 4100219904.0000 - val_mae: 22463.0840\n",
      "Epoch 2/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 581us/step - loss: 6348420608.0000 - mae: 23327.4648 - val_loss: 4056389888.0000 - val_mae: 21197.4082\n",
      "Epoch 3/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 588us/step - loss: 5998876672.0000 - mae: 22074.8906 - val_loss: 4037700864.0000 - val_mae: 20737.5137\n",
      "Epoch 4/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 584us/step - loss: 5672191488.0000 - mae: 21415.7227 - val_loss: 4030234368.0000 - val_mae: 20432.3555\n",
      "Epoch 5/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 580us/step - loss: 6110620672.0000 - mae: 21845.3105 - val_loss: 4026340096.0000 - val_mae: 20310.4336\n",
      "Epoch 6/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 580us/step - loss: 6586995200.0000 - mae: 21666.9141 - val_loss: 4023348224.0000 - val_mae: 20423.1074\n",
      "Epoch 7/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 580us/step - loss: 6393184256.0000 - mae: 21886.0957 - val_loss: 4021826816.0000 - val_mae: 20068.1367\n",
      "Epoch 8/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 584us/step - loss: 5497330176.0000 - mae: 21211.8613 - val_loss: 4020998144.0000 - val_mae: 20675.4492\n",
      "Epoch 9/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 604us/step - loss: 7009924096.0000 - mae: 22275.2129 - val_loss: 4018107904.0000 - val_mae: 20573.5215\n",
      "Epoch 10/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 593us/step - loss: 5785469952.0000 - mae: 21497.9805 - val_loss: 4016866816.0000 - val_mae: 20542.5293\n",
      "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step\n",
      "Fold MAE: 20542.538791913685\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquin/Desktop/nlp/nlp/nlpenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 605us/step - loss: 8173855232.0000 - mae: 35530.1992 - val_loss: 5592975360.0000 - val_mae: 23512.6230\n",
      "Epoch 2/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 575us/step - loss: 5025401856.0000 - mae: 22890.6055 - val_loss: 5551115264.0000 - val_mae: 22438.3281\n",
      "Epoch 3/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 563us/step - loss: 5361023488.0000 - mae: 21766.1445 - val_loss: 5524818944.0000 - val_mae: 22040.4277\n",
      "Epoch 4/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 571us/step - loss: 5361196544.0000 - mae: 21548.3535 - val_loss: 5512519168.0000 - val_mae: 21635.3398\n",
      "Epoch 5/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 574us/step - loss: 5328053248.0000 - mae: 21104.5723 - val_loss: 5507100160.0000 - val_mae: 21605.2871\n",
      "Epoch 6/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 592us/step - loss: 5997877760.0000 - mae: 21438.0840 - val_loss: 5503533056.0000 - val_mae: 21382.5371\n",
      "Epoch 7/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 562us/step - loss: 6328462848.0000 - mae: 21909.1328 - val_loss: 5502157312.0000 - val_mae: 21070.5859\n",
      "Epoch 8/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 563us/step - loss: 6134743552.0000 - mae: 21402.8730 - val_loss: 5498485248.0000 - val_mae: 21397.3047\n",
      "Epoch 9/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 563us/step - loss: 5381138944.0000 - mae: 21265.6270 - val_loss: 5496094720.0000 - val_mae: 21475.4062\n",
      "Epoch 10/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 558us/step - loss: 5236596736.0000 - mae: 20871.2793 - val_loss: 5495669248.0000 - val_mae: 21191.2969\n",
      "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step\n",
      "Fold MAE: 21191.29618064956\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquin/Desktop/nlp/nlp/nlpenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 584us/step - loss: 7063368704.0000 - mae: 34949.1523 - val_loss: 6737541632.0000 - val_mae: 24103.1641\n",
      "Epoch 2/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 566us/step - loss: 5015931392.0000 - mae: 22573.3145 - val_loss: 6680872960.0000 - val_mae: 22315.9199\n",
      "Epoch 3/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 560us/step - loss: 5170360320.0000 - mae: 21415.2773 - val_loss: 6654256640.0000 - val_mae: 21816.1621\n",
      "Epoch 4/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 564us/step - loss: 5373192192.0000 - mae: 21182.6465 - val_loss: 6645300224.0000 - val_mae: 21767.7676\n",
      "Epoch 5/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 562us/step - loss: 5449452544.0000 - mae: 21389.2617 - val_loss: 6640987136.0000 - val_mae: 21708.4004\n",
      "Epoch 6/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 567us/step - loss: 4908732928.0000 - mae: 20901.0312 - val_loss: 6638090752.0000 - val_mae: 21965.1523\n",
      "Epoch 7/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 565us/step - loss: 5342918144.0000 - mae: 21108.6328 - val_loss: 6636144128.0000 - val_mae: 21621.1191\n",
      "Epoch 8/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 557us/step - loss: 4771639808.0000 - mae: 20919.1094 - val_loss: 6634625024.0000 - val_mae: 21784.7402\n",
      "Epoch 9/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 559us/step - loss: 5702673920.0000 - mae: 21119.5137 - val_loss: 6633242112.0000 - val_mae: 21792.8965\n",
      "Epoch 10/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 568us/step - loss: 5169627648.0000 - mae: 21029.5508 - val_loss: 6632494592.0000 - val_mae: 21607.6875\n",
      "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step\n",
      "Fold MAE: 21607.698758212984\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquin/Desktop/nlp/nlp/nlpenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 580us/step - loss: 6964722688.0000 - mae: 35561.6406 - val_loss: 6608337408.0000 - val_mae: 23666.5098\n",
      "Epoch 2/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 578us/step - loss: 5926472192.0000 - mae: 23414.4414 - val_loss: 6563680768.0000 - val_mae: 22480.7539\n",
      "Epoch 3/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 621us/step - loss: 5041139712.0000 - mae: 21980.2793 - val_loss: 6539256320.0000 - val_mae: 21783.4531\n",
      "Epoch 4/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 673us/step - loss: 5386603520.0000 - mae: 21309.8457 - val_loss: 6529076736.0000 - val_mae: 21710.8848\n",
      "Epoch 5/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 607us/step - loss: 4953451520.0000 - mae: 21086.4668 - val_loss: 6524550656.0000 - val_mae: 21881.9062\n",
      "Epoch 6/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 581us/step - loss: 5480309248.0000 - mae: 21381.0195 - val_loss: 6522621952.0000 - val_mae: 21329.3066\n",
      "Epoch 7/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 571us/step - loss: 4681539584.0000 - mae: 20708.4961 - val_loss: 6517951488.0000 - val_mae: 21923.6738\n",
      "Epoch 8/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 574us/step - loss: 4898159616.0000 - mae: 21064.3945 - val_loss: 6516189696.0000 - val_mae: 22078.1816\n",
      "Epoch 9/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 567us/step - loss: 5280594944.0000 - mae: 21420.2773 - val_loss: 6513111552.0000 - val_mae: 21559.7969\n",
      "Epoch 10/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 568us/step - loss: 5569648640.0000 - mae: 21244.7520 - val_loss: 6512427008.0000 - val_mae: 21434.1602\n",
      "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step\n",
      "Fold MAE: 21434.16752829545\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquin/Desktop/nlp/nlp/nlpenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 548us/step - loss: 7431709184.0000 - mae: 35369.4609 - val_loss: 5255010816.0000 - val_mae: 23163.4062\n",
      "Epoch 2/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 531us/step - loss: 6188959744.0000 - mae: 23431.6445 - val_loss: 5212799488.0000 - val_mae: 22124.8828\n",
      "Epoch 3/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 528us/step - loss: 5697991680.0000 - mae: 22253.4590 - val_loss: 5186149888.0000 - val_mae: 21367.3086\n",
      "Epoch 4/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 578us/step - loss: 5967199232.0000 - mae: 21844.6895 - val_loss: 5172986368.0000 - val_mae: 21197.7500\n",
      "Epoch 5/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 564us/step - loss: 5697931264.0000 - mae: 21517.6328 - val_loss: 5166777344.0000 - val_mae: 20915.9961\n",
      "Epoch 6/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 528us/step - loss: 5985328640.0000 - mae: 21709.2383 - val_loss: 5163165696.0000 - val_mae: 20870.8359\n",
      "Epoch 7/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 540us/step - loss: 5658566144.0000 - mae: 21223.0469 - val_loss: 5160506880.0000 - val_mae: 21269.8652\n",
      "Epoch 8/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 555us/step - loss: 5261302272.0000 - mae: 20934.2559 - val_loss: 5157867008.0000 - val_mae: 21084.0527\n",
      "Epoch 9/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 543us/step - loss: 5617093632.0000 - mae: 21195.6035 - val_loss: 5156154368.0000 - val_mae: 21016.2520\n",
      "Epoch 10/10\n",
      "\u001b[1m4242/4242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 592us/step - loss: 6672500736.0000 - mae: 21792.0137 - val_loss: 5154767872.0000 - val_mae: 20711.3066\n",
      "\u001b[1m1061/1061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step\n",
      "Fold MAE: 20711.320212225004\n",
      "\n",
      "Cross-validated Mean MAE: 21097.4043\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['id', 'color_exterior', 'color_interior', 'tipo_combustible', 'accidente', 'marca']\n",
    "df_train = df_train.drop(columns=[col for col in columns_to_drop if col in df_train.columns])\n",
    "\n",
    "df_train['sin_daños'] = df_train['sin_daños'].fillna(\"Unknown\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df_train.drop(columns=['precio'])\n",
    "y = df_train['precio']\n",
    "\n",
    "# Encode categorical features\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X[X.select_dtypes(include=['int64', 'float64']).columns] = scaler.fit_transform(X.select_dtypes(include=['int64', 'float64']))\n",
    "\n",
    "# Define KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize model performance lists\n",
    "mae_scores = []\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_val).flatten()\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    mae_scores.append(mae)\n",
    "    print(f\"Fold MAE: {mae}\")\n",
    "\n",
    "# Report the cross-validated mean MAE\n",
    "print(f\"\\nCross-validated Mean MAE: {np.mean(mae_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 135744 entries, 0 to 169678\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   numero       135744 non-null  float64\n",
      " 1   modelo       135744 non-null  float64\n",
      " 2   año_modelo   135744 non-null  float64\n",
      " 3   millaje      135744 non-null  float64\n",
      " 4   motor        135744 non-null  float64\n",
      " 5   transmisión  135744 non-null  float64\n",
      " 6   sin_daños    135744 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 8.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18854 entries, 0 to 18853\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   numero       18854 non-null  float64\n",
      " 1   modelo       18854 non-null  float64\n",
      " 2   año_modelo   18854 non-null  float64\n",
      " 3   millaje      18854 non-null  float64\n",
      " 4   motor        18854 non-null  float64\n",
      " 5   transmisión  18854 non-null  float64\n",
      " 6   sin_daños    18854 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 1.0 MB\n",
      "None\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step\n",
      "Predictions have been saved to 'predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load the guess.csv\n",
    "guess_df = pd.read_csv('../resources/guess.csv')\n",
    "\n",
    "# Drop the same columns as in training\n",
    "columns_to_drop = ['color_exterior', 'color_interior', 'tipo_combustible', 'accidente', 'marca', 'precio']\n",
    "guess_df = guess_df.drop(columns=[col for col in columns_to_drop if col in guess_df.columns])\n",
    "\n",
    "guess_df['sin_daños'] = guess_df['sin_daños'].fillna(\"Unknown\")\n",
    "\n",
    "# Separate the 'id' column to use it later in the output\n",
    "id_column = guess_df['id']\n",
    "guess_df = guess_df.drop(columns=['id'])\n",
    "\n",
    "# Encode categorical features in the guess data\n",
    "for col in guess_df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    guess_df[col] = le.fit_transform(guess_df[col])\n",
    "\n",
    "# Scale numeric features (same scaling used for training)\n",
    "scaler = StandardScaler()\n",
    "guess_df[guess_df.select_dtypes(include=['int64', 'float64']).columns] = scaler.fit_transform(guess_df.select_dtypes(include=['int64', 'float64']))\n",
    "\n",
    "print(guess_df.info())\n",
    "# Make predictions\n",
    "predictions = model.predict(guess_df).flatten()\n",
    "\n",
    "# Create a DataFrame with 'id' and 'prediction' columns\n",
    "output_df = pd.DataFrame({\n",
    "    'id': id_column,\n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv('../output/predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved to 'predictions.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
